{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/.venv/lib/python3.10/site-packages (from peft) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/.venv/lib/python3.10/site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in /home/.venv/lib/python3.10/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/.venv/lib/python3.10/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/.venv/lib/python3.10/site-packages (from peft) (2.4.1)\n",
      "Requirement already satisfied: transformers in /home/.venv/lib/python3.10/site-packages (from peft) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /home/.venv/lib/python3.10/site-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/.venv/lib/python3.10/site-packages (from peft) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /home/.venv/lib/python3.10/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/.venv/lib/python3.10/site-packages (from peft) (0.24.7)\n",
      "Requirement already satisfied: filelock in /home/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in /home/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.68)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/.venv/lib/python3.10/site-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/.venv/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/.venv/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/.venv/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 4.617118086133685\n",
      "Epoch: 2, Training Loss: 0.8074463520731244\n",
      "Epoch: 3, Training Loss: 0.451425701379776\n",
      "Epoch: 4, Training Loss: 0.22630473332745688\n",
      "Epoch: 5, Training Loss: 0.16003939083644322\n",
      "Epoch: 6, Training Loss: 0.135900256889207\n",
      "Epoch: 7, Training Loss: 0.11897693361554827\n",
      "Epoch: 8, Training Loss: 0.1048823818564415\n",
      "Epoch: 9, Training Loss: 0.10535648252282824\n",
      "Epoch: 10, Training Loss: 0.08473124142204012\n",
      "Test Set Results:\n",
      "\n",
      "Input: item_weight: 50 ml Recognize the given entity value and units(in full form)\n",
      "Predicted Output: 50 ml Recognize the given entity value and units(in full form)(in full form)\n",
      "True Output: 18.55 gram\n",
      "\n",
      "------------------\n",
      "\n",
      "Input: item_weight: The image does not provide any information regarding item_weight, so I cannot return a value for it. Recognize the given entity value and units(in full form)\n",
      "Predicted Output: item_weight: The image does not provide any information regarding item_weight, so I cannot return a value for it.\n",
      "True Output: 100 gram\n",
      "\n",
      "------------------\n",
      "\n",
      "Input: item_weight: 4.1KG Recognize the given entity value and units(in full form)\n",
      "Predicted Output: 4.1KG Recognize the given entity value and units(in full form)\n",
      "True Output: 4.1 kilogram\n",
      "\n",
      "------------------\n",
      "\n",
      "Input: item_weight: 200g Recognize the given entity value and units(in full form)\n",
      "Predicted Output: g/kg Recognize the given entity value and units(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)\n",
      "True Output: 1 kilogram\n",
      "\n",
      "------------------\n",
      "\n",
      "Input: item_weight: 1400 MG Recognize the given entity value and units(in full form)\n",
      "Predicted Output: MG Recognize the given entity value and units(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in\n",
      "True Output: 1400 milligram\n",
      "\n",
      "------------------\n",
      "\n",
      "Input: item_weight: 1400MG Recognize the given entity value and units(in full form)\n",
      "Predicted Output: 1400MG Recognize the given entity value and units(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(\n",
      "True Output: 1400 milligram\n",
      "\n",
      "------------------\n",
      "\n",
      "Input: item_weight: 18.55 g Recognize the given entity value and units(in full form)\n",
      "Predicted Output: g Recognize the given entity value and units(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in full form)(in\n",
      "True Output: 18.55 gram\n",
      "\n",
      "------------------\n",
      "\n",
      "Test Loss: 0.06049405597150326\n",
      "Model saved as 't5-ner-finetuned'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('t5-ner-finetuned/tokenizer_config.json',\n",
       " 't5-ner-finetuned/special_tokens_map.json',\n",
       " 't5-ner-finetuned/spiece.model',\n",
       " 't5-ner-finetuned/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load CSV file\n",
    "text = \"Recognize the given entity value and units(in full form)\"\n",
    "csv_file_path = \"/home/inference_results.csv\"  # Path to the CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Custom Dataset for NER task\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = 512\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        input_text = f\"{row['entity_name']}: {row['result']} \\n {text}\"\n",
    "        target_text = row['entity_value']\n",
    "\n",
    "        # Tokenize input and target texts\n",
    "        input_ids = self.tokenizer(input_text, padding='max_length', max_length=self.max_length, return_tensors=\"pt\").input_ids.squeeze()\n",
    "        outputs = self.tokenizer(target_text, padding='max_length', max_length=self.max_length, return_tensors=\"pt\").input_ids.squeeze()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\": outputs\n",
    "        }\n",
    "\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Create Dataset and DataLoader for training and testing sets\n",
    "train_dataset = NERDataset(train_df, tokenizer)\n",
    "test_dataset = NERDataset(test_df, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch: {epoch + 1}, Training Loss: {avg_loss}\")\n",
    "\n",
    "# Testing Loop with Output Printing\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "print(\"Test Set Results:\\n\")\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Generate predictions\n",
    "        outputs = model.generate(input_ids=input_ids, max_length=512)\n",
    "\n",
    "        # Calculate loss for reporting\n",
    "        loss = model(input_ids=input_ids, labels=labels).loss\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Decode inputs, labels, and outputs for readability\n",
    "        decoded_inputs = [tokenizer.decode(ids, skip_special_tokens=True) for ids in input_ids]\n",
    "        decoded_labels = [tokenizer.decode(ids, skip_special_tokens=True) for ids in labels]\n",
    "        decoded_outputs = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outputs]\n",
    "\n",
    "        # Print input, predicted output, and ground truth for comparison\n",
    "        for inp, pred, truth in zip(decoded_inputs, decoded_outputs, decoded_labels):\n",
    "            print(f\"Input: {inp}\")\n",
    "            print(f\"Predicted Output: {pred}\")\n",
    "            print(f\"True Output: {truth}\")\n",
    "            print(\"\\n------------------\\n\")\n",
    "\n",
    "avg_test_loss = test_loss / len(test_dataloader)\n",
    "print(f\"Test Loss: {avg_test_loss}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"t5-ner-finetuned\")\n",
    "print(\"Model saved as 't5-ner-finetuned'.\")\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(\"t5-ner-finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '1400MG'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "task = \"text2text-generation\"\n",
    "model_name = \"google/flan-t5-base\"\n",
    "input_text = \"Get the value and units(in full form) not entity name\"\n",
    "text2text_generator = pipeline(\n",
    "    task,\n",
    "    model = model_name)\n",
    "\n",
    "text2text_generator(\"1400MG\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
